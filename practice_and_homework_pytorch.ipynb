{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HmsFABwClrsS"
   },
   "source": [
    "## Seminar and homework (10 points total)\n",
    "\n",
    "Today we shall compose encoder-decoder neural networks and apply them to the task of machine translation.\n",
    "\n",
    "![img](https://esciencegroup.files.wordpress.com/2016/03/seq2seq.jpg)\n",
    "_(img: esciencegroup.files.wordpress.com)_\n",
    "\n",
    "\n",
    "Encoder-decoder architectures are about converting anything to anything, including\n",
    " * Machine translation and spoken dialogue systems\n",
    " * [Image captioning](http://mscoco.org/dataset/#captions-challenge2015) and [image2latex](https://openai.com/requests-for-research/#im2latex) (convolutional encoder, recurrent decoder)\n",
    " * Generating [images by captions](https://arxiv.org/abs/1511.02793) (recurrent encoder, convolutional decoder)\n",
    " * Grapheme2phoneme - convert words to transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R4N9AD2dlrsU"
   },
   "source": [
    "## Our task: machine translation\n",
    "\n",
    "We gonna try our encoder-decoder models on russian to english machine translation problem. More specifically, we'll translate hotel and hostel descriptions. This task shows the scale of machine translation while not requiring you to train your model for weeks if you don't use GPU.\n",
    "\n",
    "Before we get to the architecture, there's some preprocessing to be done. ~~Go tokenize~~ Alright, this time we've done preprocessing for you. As usual, the data will be tokenized with WordPunctTokenizer.\n",
    "\n",
    "However, there's one more thing to do. Our data lines contain unique rare words. If we operate on a word level, we will have to deal with large vocabulary size. If instead we use character-level models, it would take lots of iterations to process a sequence. This time we're gonna pick something inbetween.\n",
    "\n",
    "One popular approach is called [Byte Pair Encoding](https://github.com/rsennrich/subword-nmt) aka __BPE__. The algorithm starts with a character-level tokenization and then iteratively merges most frequent pairs for N iterations. This results in frequent words being merged into a single token and rare words split into syllables or even characters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CfvojjHQlrsU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "�訡�� � ᨭ⠪�� �������.\n",
      "\"wget\" �� ���� ����७��� ��� ���譥�\n",
      "��������, �ᯮ��塞�� �ணࠬ��� ��� ������ 䠩���.\n",
      "\"wget\" �� ���� ����७��� ��� ���譥�\n",
      "��������, �ᯮ��塞�� �ணࠬ��� ��� ������ 䠩���.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch>=1.3.0\n",
    "!pip3 install subword-nmt &> log\n",
    "!wget https://www.dropbox.com/s/yy2zqh34dyhv07i/data.txt?dl=1 -O data.txt\n",
    "!wget https://raw.githubusercontent.com/yandexdataschool/nlp_course/2020/week04_seq2seq/vocab.py -O vocab.py\n",
    "# thanks to tilda and deephack teams for the data, Dmitry Emelyanenko for the code :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g9kP0SdxlrsY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:07<00:00, 1061.49it/s]\n",
      "100%|██████████| 8000/8000 [00:09<00:00, 861.03it/s] \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n",
    "tokenizer = WordPunctTokenizer()\n",
    "def tokenize(x):\n",
    "    return ' '.join(tokenizer.tokenize(x.lower()))\n",
    "\n",
    "# split and tokenize the data\n",
    "with open('train.en', 'w', encoding='utf-8') as f_src,  open('train.ru', 'w', encoding='utf-8') as f_dst:\n",
    "    for line in open('data.txt', encoding='utf-8'):\n",
    "        src_line, dst_line = line.strip().split('\\t')\n",
    "        f_src.write(tokenize(src_line) + '\\n')\n",
    "        f_dst.write(tokenize(dst_line) + '\\n')\n",
    "\n",
    "# build and apply bpe vocs\n",
    "bpe = {}\n",
    "for lang in ['en', 'ru']:\n",
    "    learn_bpe(open('./train.' + lang, encoding='utf-8'), open('bpe_rules.' + lang, 'w', encoding='utf-8'), num_symbols=8000)\n",
    "    bpe[lang] = BPE(open('./bpe_rules.' + lang, encoding='utf-8'))\n",
    "    \n",
    "    with open('train.bpe.' + lang, 'w', encoding='utf-8') as f_out:\n",
    "        for line in open('train.' + lang, encoding='utf-8'):\n",
    "            f_out.write(bpe[lang].process_line(line.strip()) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A qu@@ i@@ ck bro@@ wn fo@@ x ju@@ mp@@ s o@@ ver the la@@ zy do@@ g'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe['ru'].process_line(\"A quick brown fox jumps over the lazy dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A quick bro@@ wn fo@@ x j@@ um@@ ps over the laz@@ y dog'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe['en'].process_line(\"A quick brown fox jumps over the lazy dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0UPW3sV8lrsb"
   },
   "source": [
    "### Building vocabularies\n",
    "\n",
    "We now need to build vocabularies that map strings to token ids and vice versa. We're gonna need these fellas when we feed training data into model or convert output matrices into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CmTy_m_olrsb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8PskgBSxlrsd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp: на территории обустроена бесплатная частная парковка .\n",
      "out: free private parking is available on site .\n",
      "\n",
      "inp: кроме того , в 5 минутах ходьбы работают многочисленные бары и рестораны .\n",
      "out: guests can find many bars and restaurants within a 5 - minute walk .\n",
      "\n",
      "inp: отель san mi@@ gu@@ el расположен в центре мор@@ ели@@ и , в 750 метрах от главной площади города и кафедрального собора .\n",
      "out: hotel san miguel is located in central more@@ lia , 750 metres from the city ’ s main square and cathedral .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_inp = np.array(open('./train.bpe.ru', encoding='utf-8').read().split('\\n'))\n",
    "data_out = np.array(open('./train.bpe.en', encoding='utf-8').read().split('\\n'))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_inp, dev_inp, train_out, dev_out = train_test_split(data_inp, data_out, test_size=3000,\n",
    "                                                          random_state=42)\n",
    "for i in range(3):\n",
    "    print('inp:', train_inp[i])\n",
    "    print('out:', train_out[i], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vipg4O61lrsg"
   },
   "outputs": [],
   "source": [
    "from vocab import Vocab\n",
    "inp_voc = Vocab.from_lines(train_inp)\n",
    "out_voc = Vocab.from_lines(train_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cwOoHfuhlrsi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines\n",
      "['гостевой дом r .', 'до афин — 20 км .', 'работает боулинг .', 'оборудован балкон .', 'подключен wi - fi .']\n",
      "\n",
      "words to ids (0 = bos, 1 = eos):\n",
      "tensor([[   0, 2688, 2943, 1108,   29,    1,    1,    1],\n",
      "        [   0, 2922, 1834, 8035,   59, 3800,   29,    1],\n",
      "        [   0, 6030, 2083,   29,    1,    1,    1,    1],\n",
      "        [   0, 4927, 1870,   29,    1,    1,    1,    1],\n",
      "        [   0, 5549, 1453,   27,  592,   29,    1,    1]])\n",
      "\n",
      "back to words\n",
      "['гостевой дом r .', 'до афин — 20 км .', 'работает боулинг .', 'оборудован балкон .', 'подключен wi - fi .']\n"
     ]
    }
   ],
   "source": [
    "# Here's how you cast lines into ids and backwards.\n",
    "batch_lines = sorted(train_inp, key=len)[5:10]\n",
    "batch_ids = inp_voc.to_matrix(batch_lines)\n",
    "batch_lines_restored = inp_voc.to_lines(batch_ids)\n",
    "\n",
    "print(\"lines\")\n",
    "print(batch_lines)\n",
    "print(\"\\nwords to ids (0 = bos, 1 = eos):\")\n",
    "print(batch_ids)\n",
    "print(\"\\nback to words\")\n",
    "print(batch_lines_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gSYu-MkElrsk"
   },
   "source": [
    "Draw source and translation length distributions to estimate the scope of the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TLLl9cSNlrsl"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(map(len, map(str.split, train_inp))), bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(map(len, map(str.split, train_out))), bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BHWgx34flrsn"
   },
   "source": [
    "### Encoder-decoder model\n",
    "\n",
    "The code below contains a template for a simple encoder-decoder model: single GRU encoder/decoder, no attention or anything. This model is implemented for you as a reference and a baseline for your homework assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pd_rDRm9lrso"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgfN5-F7lrst"
   },
   "outputs": [],
   "source": [
    "class BasicModel(nn.Module):\n",
    "    def __init__(self, inp_voc, out_voc, emb_size=64, hid_size=128):\n",
    "        \"\"\"\n",
    "        A simple encoder-decoder seq2seq model\n",
    "        \"\"\"\n",
    "        super().__init__() # initialize base class to track sub-layers, parameters, etc.\n",
    "\n",
    "        self.inp_voc, self.out_voc = inp_voc, out_voc\n",
    "        self.hid_size = hid_size\n",
    "        \n",
    "        self.emb_inp = nn.Embedding(len(inp_voc), emb_size)\n",
    "        self.emb_out = nn.Embedding(len(out_voc), emb_size)\n",
    "        self.enc0 = nn.GRU(emb_size, hid_size, batch_first=True)\n",
    "\n",
    "        self.dec_start = nn.Linear(hid_size, hid_size)\n",
    "        self.dec0 = nn.GRUCell(emb_size, hid_size)\n",
    "        self.logits = nn.Linear(hid_size, len(out_voc))\n",
    "        \n",
    "    def forward(self, inp, out):\n",
    "        \"\"\" Apply model in training mode \"\"\"\n",
    "        initial_state = self.encode(inp)\n",
    "        return self.decode(initial_state, out)\n",
    "\n",
    "\n",
    "    def encode(self, inp, **flags):\n",
    "        \"\"\"\n",
    "        Takes symbolic input sequence, computes initial state\n",
    "        :param inp: matrix of input tokens [batch, time]\n",
    "        :returns: initial decoder state tensors, one or many\n",
    "        \"\"\"\n",
    "        inp_emb = self.emb_inp(inp)\n",
    "        batch_size = inp.shape[0]\n",
    "        \n",
    "        enc_seq, [last_state_but_not_really] = self.enc0(inp_emb)\n",
    "        # enc_seq: [batch, time, hid_size], last_state: [batch, hid_size]\n",
    "        \n",
    "        # note: last_state is not _actually_ last because of padding, let's find the real last_state\n",
    "        lengths = (inp != self.inp_voc.eos_ix).to(torch.int64).sum(dim=1).clamp_max(inp.shape[1] - 1)\n",
    "        last_state = enc_seq[torch.arange(len(enc_seq)), lengths]\n",
    "        # ^-- shape: [batch_size, hid_size]\n",
    "        \n",
    "        dec_start = self.dec_start(last_state)\n",
    "        return [dec_start]\n",
    "\n",
    "    def decode_step(self, prev_state, prev_tokens, **flags):\n",
    "        \"\"\"\n",
    "        Takes previous decoder state and tokens, returns new state and logits for next tokens\n",
    "        :param prev_state: a list of previous decoder state tensors, same as returned by encode(...)\n",
    "        :param prev_tokens: previous output tokens, an int vector of [batch_size]\n",
    "        :return: a list of next decoder state tensors, a tensor of logits [batch, len(out_voc)]\n",
    "        \"\"\"\n",
    "        [dec_start] = prev_state\n",
    "        \n",
    "        prev_tokens_emb = self.emb_out(prev_tokens)\n",
    "        \n",
    "        new_gru_activations = self.dec0(prev_tokens_emb, dec_start)\n",
    "        new_dec_state = [new_gru_activations]\n",
    "        output_logits = self.logits(new_gru_activations)\n",
    "\n",
    "        return new_dec_state, output_logits\n",
    "\n",
    "    def decode(self, initial_state, out_tokens, **flags):\n",
    "        \"\"\" Iterate over reference tokens (out_tokens) with decode_step \"\"\"\n",
    "        batch_size = out_tokens.shape[0]\n",
    "        state = initial_state\n",
    "        \n",
    "        # initial logits: always predict BOS\n",
    "        onehot_bos = F.one_hot(torch.full([batch_size], self.out_voc.bos_ix, dtype=torch.int64),\n",
    "                               num_classes=len(self.out_voc)).to(device=out_tokens.device)\n",
    "        first_logits = torch.log(onehot_bos.to(torch.float32) + 1e-9)\n",
    "        \n",
    "        logits_sequence = [first_logits]\n",
    "        for i in range(out_tokens.shape[1] - 1):\n",
    "            state, logits = self.decode_step(state, out_tokens[:, i])\n",
    "            logits_sequence.append(logits)\n",
    "        return torch.stack(logits_sequence, dim=1)\n",
    "\n",
    "    def decode_inference(self, initial_state, max_len=100, **flags):\n",
    "        \"\"\" Generate translations from model (greedy version) \"\"\"\n",
    "        batch_size, device = len(initial_state[0]), initial_state[0].device\n",
    "        state = initial_state\n",
    "        outputs = [torch.full([batch_size], self.out_voc.bos_ix, dtype=torch.int64, \n",
    "                              device=device)]\n",
    "        all_states = [initial_state]\n",
    "\n",
    "        for i in range(max_len):\n",
    "            state, logits = self.decode_step(state, outputs[-1])\n",
    "            outputs.append(logits.argmax(dim=-1))\n",
    "            all_states.append(state)\n",
    "        \n",
    "        return torch.stack(outputs, dim=1), all_states\n",
    "\n",
    "    def translate_lines(self, inp_lines, **kwargs):\n",
    "        inp = self.inp_voc.to_matrix(inp_lines).to(device)\n",
    "        initial_state = self.encode(inp)\n",
    "        out_ids, states = self.decode_inference(initial_state, **kwargs)\n",
    "        return self.out_voc.to_lines(out_ids.cpu().numpy()), states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging area\n",
    "model = BasicModel(inp_voc, out_voc).to(device)\n",
    "\n",
    "dummy_inp_tokens = inp_voc.to_matrix(sorted(train_inp, key=len)[5:10]).to(device)\n",
    "dummy_out_tokens = out_voc.to_matrix(sorted(train_out, key=len)[5:10]).to(device)\n",
    "\n",
    "h0 = model.encode(dummy_inp_tokens)\n",
    "h1, logits1 = model.decode_step(h0, torch.arange(len(dummy_inp_tokens), device=device))\n",
    "\n",
    "assert isinstance(h1, list) and len(h1) == len(h0)\n",
    "assert h1[0].shape == h0[0].shape and not torch.allclose(h1[0], h0[0])\n",
    "assert logits1.shape == (len(dummy_inp_tokens), len(out_voc))\n",
    "\n",
    "logits_seq = model.decode(h0, dummy_out_tokens)\n",
    "assert logits_seq.shape == (dummy_out_tokens.shape[0], dummy_out_tokens.shape[1], len(out_voc))\n",
    "\n",
    "# full forward\n",
    "logits_seq2 = model(dummy_inp_tokens, dummy_out_tokens)\n",
    "assert logits_seq2.shape == logits_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 7, 7801])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_seq2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translations without training:\n",
      "dy@@ ® elect@@ tar vico maj@@ gateway wse designated swiss 700 lifts tana ü@@ venetian washed greek super@@ hua deliveries ini delle rom@@ loungers edin@@\n",
      "dy@@ ® elect@@ tar vico maj@@ gateway wse designated swiss 700 lifts tana ü@@ venetian washed greek super@@ hua deliveries ini delle rom@@ loungers edin@@\n",
      "dy@@ ® elect@@ tar vico maj@@ gateway wse designated swiss 700 lifts tana ü@@ venetian washed greek super@@ hua deliveries ini delle rom@@ loungers edin@@\n"
     ]
    }
   ],
   "source": [
    "dummy_translations, dummy_states = model.translate_lines(train_inp[:3], max_len=25)\n",
    "print(\"Translations without training:\")\n",
    "print('\\n'.join([line for line in dummy_translations]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_wuv1-aVlrs0"
   },
   "source": [
    "### Training loss (2 points)\n",
    "\n",
    "Our training objective is almost the same as it was for neural language models:\n",
    "$$ L = {\\frac1{|D|}} \\sum_{X, Y \\in D} \\sum_{y_t \\in Y} - \\log p(y_t \\mid y_1, \\dots, y_{t-1}, X, \\theta) $$\n",
    "\n",
    "where $|D|$ is the __total length of all sequences__, including BOS and first EOS, but excluding PAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8XPV8sWlrs5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_loss(model, inp, out, **flags):\n",
    "    \"\"\"\n",
    "    Compute loss (float32 scalar) as in the formula above\n",
    "    :param inp: input tokens matrix, int32[batch, time]\n",
    "    :param out: reference tokens matrix, int32[batch, time]\n",
    "    \n",
    "    In order to pass the tests, your function should\n",
    "    * include loss at first EOS but not the subsequent ones\n",
    "    * divide sum of losses by a sum of input lengths (use voc.compute_mask)\n",
    "    \"\"\"\n",
    "    mask = model.out_voc.compute_mask(out) # [batch_size, out_len]\n",
    "    targets_1hot = F.one_hot(out, len(model.out_voc)).to(torch.float32)\n",
    "    \n",
    "    # outputs of the model, [batch_size, out_len, num_tokens]\n",
    "    logits_seq = model(inp, out)\n",
    "\n",
    "    # log-probabilities of all tokens at all steps, [batch_size, out_len, num_tokens]\n",
    "    logprobs_seq = torch.log_softmax(logits_seq, dim=-1)\n",
    "   \n",
    "    # log-probabilities of correct outputs, [batch_size, out_len]\n",
    "    logp_out = (logprobs_seq * targets_1hot).sum(dim=-1)\n",
    "    # ^-- this will select the probability of the actual next token.\n",
    "    # Note: you can compute loss more efficiently using using F.cross_entropy\n",
    "\n",
    "    # average cross-entropy over tokens where mask == True\n",
    "    return -logp_out.mean() # average loss, scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.7377, device='cuda:0', grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_loss = compute_loss(model, dummy_inp_tokens, dummy_out_tokens)\n",
    "dummy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True,  True, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True, False, False, False],\n",
       "        [ True,  True,  True,  True,  True, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True, False]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.out_voc.compute_mask(dummy_inp_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ME_LWUeklrs7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(7.7377, device='cuda:0', grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dummy_loss = compute_loss(model, dummy_inp_tokens, dummy_out_tokens)\n",
    "print(\"Loss:\", dummy_loss)\n",
    "assert np.allclose(dummy_loss.item(), 7.5, rtol=0.1, atol=0.1), \"We're sorry for your loss\"\n",
    "\n",
    "# test autograd\n",
    "dummy_loss.backward()\n",
    "for name, param in model.named_parameters():\n",
    "    assert param.grad is not None and abs(param.grad.max()) != 0, f\"Param {name} received no gradients\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HpbaBpW7lrs-"
   },
   "source": [
    "### Evaluation: BLEU\n",
    "\n",
    "Machine translation is commonly evaluated with [BLEU](https://en.wikipedia.org/wiki/BLEU) score. This metric simply computes which fraction of predicted n-grams is actually present in the reference translation. It does so for n=1,2,3 and 4 and computes the geometric average with penalty if translation is shorter than reference.\n",
    "\n",
    "While BLEU [has many drawbacks](http://www.cs.jhu.edu/~ccb/publications/re-evaluating-the-role-of-bleu-in-mt-research.pdf), it still remains the most commonly used metric and one of the simplest to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gb1-PhKIlrs-"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "def compute_bleu(model, inp_lines, out_lines, bpe_sep='@@ ', **flags):\n",
    "    \"\"\"\n",
    "    Estimates corpora-level BLEU score of model's translations given inp and reference out\n",
    "    Note: if you're serious about reporting your results, use https://pypi.org/project/sacrebleu\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        translations, _ = model.translate_lines(inp_lines, **flags)\n",
    "        translations = [line.replace(bpe_sep, '') for line in translations]\n",
    "        actual = [line.replace(bpe_sep, '') for line in out_lines]\n",
    "        return corpus_bleu(\n",
    "            [[ref.split()] for ref in actual],\n",
    "            [trans.split() for trans in translations],\n",
    "            smoothing_function=lambda precisions, **kw: [p + 1.0 / p.denominator for p in precisions]\n",
    "            ) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gZvfid1RlrtA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0015999030795418256"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_bleu(model, dev_inp, dev_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nQDhGwg4lrtC"
   },
   "source": [
    "### Training loop\n",
    "\n",
    "Training encoder-decoder models isn't that different from any other models: sample batches, compute loss, backprop and update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yfwIaixHlrtI",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm, trange\n",
    "metrics = {'train_loss': [], 'dev_bleu': [] }\n",
    "\n",
    "model = BasicModel(inp_voc, out_voc).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LlDT6eDUlrtL",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss=0.856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [45:18<00:00,  9.20it/s]\n"
     ]
    }
   ],
   "source": [
    "for _ in trange(25000):\n",
    "    step = len(metrics['train_loss']) + 1\n",
    "    batch_ix = np.random.randint(len(train_inp), size=batch_size)\n",
    "    batch_inp = inp_voc.to_matrix(train_inp[batch_ix]).to(device)\n",
    "    batch_out = out_voc.to_matrix(train_out[batch_ix]).to(device)\n",
    "    \n",
    "    loss_t = compute_loss(model, batch_inp, batch_out)\n",
    "    opt.zero_grad()\n",
    "    loss_t.backward()\n",
    "    opt.step()\n",
    "\n",
    "    metrics['train_loss'].append((step, loss_t.item()))\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        metrics['dev_bleu'].append((step, compute_bleu(model, dev_inp, dev_out)))\n",
    "        \n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(12,4))\n",
    "        for i, (name, history) in enumerate(sorted(metrics.items())):\n",
    "            plt.subplot(1, len(metrics), i + 1)\n",
    "            plt.title(name)\n",
    "            plt.plot(*zip(*history))\n",
    "            plt.grid()\n",
    "        plt.show()\n",
    "        print(\"Mean loss=%.3f\" % np.mean(metrics['train_loss'][-10:], axis=0)[1], flush=True)\n",
    "        \n",
    "# Note: it's okay if bleu oscillates up and down as long as it gets better on average over long term (e.g. 5k batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ahuhKVhlrtP"
   },
   "outputs": [],
   "source": [
    "assert np.mean(metrics['dev_bleu'][-10:], axis=0)[1] > 15, \"We kind of need a higher bleu BLEU from you. Kind of right now.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KyaHOpealrtS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в распоряжении гостей общая кухня и общая гостиная .\n",
      "there is a shared kitchen and shared kitchen at the property .\n",
      "\n",
      "кроме того , предоставляется прокат велосипедов , услуги трансфера и бесплатная парковка .\n",
      "other facilities offered at the property include a bike rental and car rental services .\n",
      "\n",
      "расстояние до города ки@@ сси@@ м@@ ми составляет 26 км .\n",
      "men@@ er@@ ano is 26 km away .\n",
      "\n",
      "апартаменты в пент@@ хаусе с общим открытым бассейном , садом , кондиционером и террасой для загара расположены в 5 минутах ходьбы от пляжа на курорте ка@@ бо - рой .\n",
      "featuring a garden , sun terrace and a seasonal outdoor pool , cabañas villa features a seasonal outdoor pool .\n",
      "\n",
      "апартаменты mo@@ s@@ co@@ w point - loft red square находятся в москве , в 200 метрах от большого театра .\n",
      "located in mur@@ met@@ ia , just 10 minutes ’ walk from the bustling ty@@ pe island .\n",
      "\n",
      "в вашем распоряжении собственная ванная комната с душем и полотенцами .\n",
      "featuring a shower , private bathrooms also come with towels .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for inp_line, trans_line in zip(dev_inp[::500], model.translate_lines(dev_inp[::500])[0]):\n",
    "    print(inp_line)\n",
    "    print(trans_line)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edk_oVg0lrtW"
   },
   "source": [
    "### Your Attention Required\n",
    "\n",
    "In this section we want you to improve over the basic model by implementing a simple attention mechanism.\n",
    "\n",
    "This is gonna be a two-parter: building the __attention layer__ and using it for an __attentive seq2seq model__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qz9aROAIlrtX"
   },
   "source": [
    "### Attention layer (3 points)\n",
    "\n",
    "Here you will have to implement a layer that computes a simple additive attention:\n",
    "\n",
    "Given encoder sequence $ h^e_0, h^e_1, h^e_2, ..., h^e_T$ and a single decoder state $h^d$,\n",
    "\n",
    "* Compute logits with a 2-layer neural network\n",
    "$$a_t = linear_{out}(tanh(linear_{e}(h^e_t) + linear_{d}(h_d)))$$\n",
    "* Get probabilities from logits, \n",
    "$$ p_t = {{e ^ {a_t}} \\over { \\sum_\\tau e^{a_\\tau} }} $$\n",
    "\n",
    "* Add up encoder states with probabilities to get __attention response__\n",
    "$$ attn = \\sum_t p_t \\cdot h^e_t $$\n",
    "\n",
    "You can learn more about attention layers in the lecture slides or [from this post](https://distill.pub/2016/augmented-rnns/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, name, enc_size, dec_size, hid_size, activ=torch.tanh):\n",
    "        \"\"\" A layer that computes additive attention response and weights \"\"\"\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.enc_size = enc_size # num units in encoder state\n",
    "        self.dec_size = dec_size # num units in decoder state\n",
    "        self.hid_size = hid_size # attention layer hidden units\n",
    "        self.activ = activ       # attention layer hidden nonlinearity\n",
    "        \n",
    "        # create trainable paramteres like this:\n",
    "        # self.<PARAMETER_NAME> = nn.Parameter(<INITIAL_VALUES>, requires_grad=True)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.enc_linear = nn.Linear(enc_size, hid_size) \n",
    "        self.dec_linear = nn.Linear(dec_size, hid_size)\n",
    "        self.out_linear = nn.Linear(hid_size, 1)\n",
    "        # you will need a couple of these\n",
    "        \n",
    "\n",
    "    def forward(self, enc, dec, inp_mask):\n",
    "        \"\"\"\n",
    "        Computes attention response and weights\n",
    "        :param enc: encoder activation sequence, float32[batch_size, ninp, enc_size]\n",
    "        :param dec: single decoder state used as \"query\", float32[batch_size, dec_size]\n",
    "        :param inp_mask: mask on enc activatons (0 after first eos), float32 [batch_size, ninp]\n",
    "        :returns: attn[batch_size, enc_size], probs[batch_size, ninp]\n",
    "            - attn - attention response vector (weighted sum of enc)\n",
    "            - probs - attention weights after softmax\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute logits\n",
    "        # print(self.dec_linear(dec.long()))\n",
    "        # logits for each element in batch\n",
    "        logits = torch.stack([self.out_linear(self.activ(self.enc_linear(token) + self.dec_linear(dec))) for token in enc])\n",
    "\n",
    "        # Apply mask - if mask is 0, logits should be -inf or -1e9\n",
    "        # You may need torch.where\n",
    "        masked_logits = torch.where(inp_mask > 0, logits, 0)\n",
    "\n",
    "        # Compute attention probabilities (softmax)\n",
    "        \n",
    "        probs = self.softmax(masked_logits)\n",
    "\n",
    "        # Compute attention response using enc and probs\n",
    "        attn = torch.matmul(probs, enc)\n",
    "\n",
    "        return attn, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5) must match the size of tensor b (3) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll checks passed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Запускаем тест\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[43mtest_attention_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[105], line 19\u001b[0m, in \u001b[0;36mtest_attention_layer\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m inp_mask[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Маскируем последние два токена\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Применяем слой внимания\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m attn, probs \u001b[38;5;241m=\u001b[39m \u001b[43mattn_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Проверки\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttention shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[104], line 34\u001b[0m, in \u001b[0;36mAttentionLayer.forward\u001b[1;34m(self, enc, dec, inp_mask)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03mComputes attention response and weights\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m:param enc: encoder activation sequence, float32[batch_size, ninp, enc_size]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    - probs - attention weights after softmax\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Compute logits\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# print(self.dec_linear(dec.long()))\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# logits for each element in batch\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m logits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_linear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactiv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_linear(token) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec_linear(dec))) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m enc])\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Apply mask - if mask is 0, logits should be -inf or -1e9\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# You may need torch.where\u001b[39;00m\n\u001b[0;32m     38\u001b[0m masked_logits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(inp_mask \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, logits, \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[104], line 34\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03mComputes attention response and weights\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m:param enc: encoder activation sequence, float32[batch_size, ninp, enc_size]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    - probs - attention weights after softmax\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Compute logits\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# print(self.dec_linear(dec.long()))\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# logits for each element in batch\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m logits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_linear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactiv(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menc_linear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdec_linear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec\u001b[49m\u001b[43m)\u001b[49m)) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m enc])\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Apply mask - if mask is 0, logits should be -inf or -1e9\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# You may need torch.where\u001b[39;00m\n\u001b[0;32m     38\u001b[0m masked_logits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(inp_mask \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, logits, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (3) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "def test_attention_layer():\n",
    "    # Параметры для теста\n",
    "    batch_size = 3\n",
    "    seq_len = 5\n",
    "    enc_size = 10\n",
    "    dec_size = 15\n",
    "    hid_size = 20\n",
    "\n",
    "    # Создаем экземпляр AttentionLayer\n",
    "    attn_layer = AttentionLayer(\"test\", enc_size, dec_size, hid_size)\n",
    "\n",
    "    # Создаем тестовые данные\n",
    "    enc = torch.randn(batch_size, seq_len, enc_size)\n",
    "    dec = torch.randn(batch_size, dec_size)\n",
    "    inp_mask = torch.ones(batch_size, seq_len)\n",
    "    inp_mask[:, -2:] = 0  # Маскируем последние два токена\n",
    "\n",
    "    # Применяем слой внимания\n",
    "    attn, probs = attn_layer(enc, dec, inp_mask)\n",
    "\n",
    "    # Проверки\n",
    "    print(f\"Attention shape: {attn.shape}\")\n",
    "    print(f\"Probabilities shape: {probs.shape}\")\n",
    "    print(f\"Sum of probabilities: {probs.sum(dim=1)}\")\n",
    "    print(f\"Masked probabilities:\\n{probs}\")\n",
    "\n",
    "    # Проверяем, что маскированные вероятности равны нулю\n",
    "    assert torch.all(probs[:, -2:] == 0), \"Masked probabilities should be zero\"\n",
    "\n",
    "    # Проверяем, что сумма вероятностей примерно равна 1\n",
    "    assert torch.allclose(probs.sum(dim=1), torch.ones(batch_size)), \"Sum of probabilities should be close to 1\"\n",
    "\n",
    "    print(\"All checks passed!\")\n",
    "\n",
    "# Запускаем тест\n",
    "test_attention_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IalfpdAelrtb"
   },
   "source": [
    "### Seq2seq model with attention (3 points)\n",
    "\n",
    "You can now use the attention layer to build a network. The simplest way to implement attention is to use it in decoder phase:\n",
    "![img](https://i.imgur.com/6fKHlHb.png)\n",
    "_image from distill.pub [article](https://distill.pub/2016/augmented-rnns/)_\n",
    "\n",
    "On every step, use __previous__ decoder state to obtain attention response. Then feed concat this response to the inputs of next attention layer.\n",
    "\n",
    "The key implementation detail here is __model state__. Put simply, you can add any tensor into the list of `encode` outputs. You will then have access to them at each `decode` step. This may include:\n",
    "* Last RNN hidden states (as in basic model)\n",
    "* The whole sequence of encoder outputs (to attend to) and mask\n",
    "* Attention probabilities (to visualize)\n",
    "\n",
    "_There are, of course, alternative ways to wire attention into your network and different kinds of attention. Take a look at [this](https://arxiv.org/abs/1609.08144), [this](https://arxiv.org/abs/1706.03762) and [this](https://arxiv.org/abs/1808.03867) for ideas. And for image captioning/im2latex there's [visual attention](https://arxiv.org/abs/1502.03044)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCKPB5JmcE6j"
   },
   "outputs": [],
   "source": [
    "class AttentiveModel(BasicModel):\n",
    "    def __init__(self, name, inp_voc, out_voc,\n",
    "                 emb_size=64, hid_size=128, attn_size=128):\n",
    "        \"\"\" Translation model that uses attention. See instructions above. \"\"\"\n",
    "        nn.Module.__init__(self)  # initialize base class to track sub-layers, trainable variables, etc.\n",
    "        self.inp_voc, self.out_voc = inp_voc, out_voc\n",
    "        self.hid_size = hid_size\n",
    "        \n",
    "        <YOUR CODE: initialize layers>\n",
    "\n",
    "    def encode(self, inp, **flags):\n",
    "        \"\"\"\n",
    "        Takes symbolic input sequence, computes initial state\n",
    "        :param inp: matrix of input tokens [batch, time]\n",
    "        :return: a list of initial decoder state tensors\n",
    "        \"\"\"\n",
    "        \n",
    "        # encode input sequence, create initial decoder states\n",
    "        <YOUR CODE>\n",
    "        \n",
    "        # apply attention layer from initial decoder hidden state\n",
    "        first_attn_probas = <...>\n",
    "        \n",
    "        # Build first state: include\n",
    "        # * initial states for decoder recurrent layers\n",
    "        # * encoder sequence and encoder attn mask (for attention)\n",
    "        # * make sure that last state item is attention probabilities tensor\n",
    "        \n",
    "        first_state = [<...>, first_attn_probas]\n",
    "        return first_state\n",
    "   \n",
    "    def decode_step(self, prev_state, prev_tokens, **flags):\n",
    "        \"\"\"\n",
    "        Takes previous decoder state and tokens, returns new state and logits for next tokens\n",
    "        :param prev_state: a list of previous decoder state tensors\n",
    "        :param prev_tokens: previous output tokens, an int vector of [batch_size]\n",
    "        :return: a list of next decoder state tensors, a tensor of logits [batch, n_tokens]\n",
    "        \"\"\"\n",
    "        \n",
    "        <YOUR CODE HERE>\n",
    "        return [new_dec_state, output_logits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ryZCOTEslrtf"
   },
   "source": [
    "### Training attentive model\n",
    "\n",
    "Please reuse the infrastructure you've built for the regular model. I hope you didn't hard-code anything :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YMHPgZxcFaQ"
   },
   "outputs": [],
   "source": [
    "metrics = {'train_loss': [], 'dev_bleu': [] }\n",
    "\n",
    "model = AttentiveModel(\"AttentionModel\", inp_voc, out_voc).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m batch_inp \u001b[38;5;241m=\u001b[39m inp_voc\u001b[38;5;241m.\u001b[39mto_matrix(train_inp[batch_ix])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      5\u001b[0m batch_out \u001b[38;5;241m=\u001b[39m out_voc\u001b[38;5;241m.\u001b[39mto_matrix(train_out[batch_ix])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 7\u001b[0m loss_t \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_inp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      9\u001b[0m loss_t\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[1;32mIn[15], line 15\u001b[0m, in \u001b[0;36mcompute_loss\u001b[1;34m(model, inp, out, **flags)\u001b[0m\n\u001b[0;32m     12\u001b[0m targets_1hot \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mone_hot(out, \u001b[38;5;28mlen\u001b[39m(model\u001b[38;5;241m.\u001b[39mout_voc))\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# outputs of the model, [batch_size, out_len, num_tokens]\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m logits_seq \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# log-probabilities of all tokens at all steps, [batch_size, out_len, num_tokens]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m logprobs_seq \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog_softmax(logits_seq, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[97], line 24\u001b[0m, in \u001b[0;36mAttentiveModel.forward\u001b[1;34m(self, inp, out)\u001b[0m\n\u001b[0;32m     21\u001b[0m inp \u001b[38;5;241m=\u001b[39m inp\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     22\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m---> 24\u001b[0m initial_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(initial_state, out)\n",
      "Cell \u001b[1;32mIn[97], line 34\u001b[0m, in \u001b[0;36mAttentiveModel.encode\u001b[1;34m(self, inp, **flags)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, inp, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflags):\n\u001b[0;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m    Takes symbolic input sequence, computes initial state\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    :param inp: matrix of input tokens [batch, time]\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    :return: a list of initial decoder state tensors\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m     inp_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memb_inp\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     enc_seq, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc0(inp_emb)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# Create input mask\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2227\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2228\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2229\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2230\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "for _ in trange(25000):\n",
    "    step = len(metrics['train_loss']) + 1\n",
    "    batch_ix = np.random.randint(len(train_inp), size=batch_size)\n",
    "    batch_inp = inp_voc.to_matrix(train_inp[batch_ix]).to(device)\n",
    "    batch_out = out_voc.to_matrix(train_out[batch_ix]).to(device)\n",
    "    \n",
    "    loss_t = compute_loss(model, batch_inp, batch_out)\n",
    "    opt.zero_grad()\n",
    "    loss_t.backward()\n",
    "    opt.step()\n",
    "\n",
    "    metrics['train_loss'].append((step, loss_t.item()))\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        metrics['dev_bleu'].append((step, compute_bleu(model, dev_inp, dev_out)))\n",
    "        \n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(12,4))\n",
    "        for i, (name, history) in enumerate(sorted(metrics.items())):\n",
    "            plt.subplot(1, len(metrics), i + 1)\n",
    "            plt.title(name)\n",
    "            plt.plot(*zip(*history))\n",
    "            plt.grid()\n",
    "        plt.show()\n",
    "        print(\"Mean loss=%.3f\" % np.mean(metrics['train_loss'][-10:], axis=0)[1], flush=True)\n",
    "        \n",
    "# Note: it's okay if bleu oscillates up and down as long as it gets better on average over long term (e.g. 5k batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<YOUR CODE: measure final BLEU>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing model attention (2 points)\n",
    "\n",
    "After training the attentive translation model, you can check it's sanity by visualizing its attention weights.\n",
    "\n",
    "We provided you with a function that draws attention maps using [`Bokeh`](https://bokeh.pydata.org/en/latest/index.html). Once you managed to produce something better than random noise, please save at least 3 attention maps and __submit them to anytask__ alongside this notebook to get the max grade. Saving bokeh figures as __cell outputs is not enough!__ (TAs can't see saved bokeh figures in anytask). You can save bokeh images as screenshots or using this button:\n",
    "\n",
    "![bokeh_panel](https://github.com/yandexdataschool/nlp_course/raw/2019/resources/bokeh_panel.png)\n",
    "\n",
    "__Note:__ you're not locked into using bokeh. If you prefer a different visualization method, feel free to use that instead of bokeh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.plotting as pl\n",
    "import bokeh.models as bm\n",
    "from bokeh.io import output_notebook, show\n",
    "output_notebook()\n",
    "\n",
    "def draw_attention(inp_line, translation, probs):\n",
    "    \"\"\" An intentionally ambiguous function to visualize attention weights \"\"\"\n",
    "    inp_tokens = inp_voc.tokenize(inp_line)\n",
    "    trans_tokens = out_voc.tokenize(translation)\n",
    "    probs = probs[:len(trans_tokens), :len(inp_tokens)]\n",
    "    \n",
    "    fig = pl.figure(x_range=(0, len(inp_tokens)), y_range=(0, len(trans_tokens)),\n",
    "                    x_axis_type=None, y_axis_type=None, tools=[])\n",
    "    fig.image([probs[::-1]], 0, 0, len(inp_tokens), len(trans_tokens))\n",
    "\n",
    "    fig.add_layout(bm.LinearAxis(axis_label='source tokens'), 'above')\n",
    "    fig.xaxis.ticker = np.arange(len(inp_tokens)) + 0.5\n",
    "    fig.xaxis.major_label_overrides = dict(zip(np.arange(len(inp_tokens)) + 0.5, inp_tokens))\n",
    "    fig.xaxis.major_label_orientation = 45\n",
    "\n",
    "    fig.add_layout(bm.LinearAxis(axis_label='translation tokens'), 'left')\n",
    "    fig.yaxis.ticker = np.arange(len(trans_tokens)) + 0.5\n",
    "    fig.yaxis.major_label_overrides = dict(zip(np.arange(len(trans_tokens)) + 0.5, trans_tokens[::-1]))\n",
    "\n",
    "    show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = dev_inp[::500]\n",
    "\n",
    "trans, states = model.translate_lines(inp)\n",
    "\n",
    "# select attention probs from model state (you may need to change this for your custom model)\n",
    "# attention_probs below must have shape [batch_size, translation_length, input_length], extracted from states\n",
    "# e.g. if attention probs are at the end of each state, use np.stack([state[-1] for state in states], axis=1)\n",
    "attention_probs = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    draw_attention(inp[i], trans[i], attention_probs[i])\n",
    "    \n",
    "# Does it look fine already? don't forget to save images for anytask!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note 1:__ If the attention maps are not iterpretable, try starting encoder from zeros (instead of dec_start), forcing model to use attention.\n",
    "\n",
    "__Note 2:__ If you're studying this course as a YSDA student, please submit __attention screenshots__ alongside your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbIIngNVlrtt"
   },
   "source": [
    "## Goind deeper (2++ points each)\n",
    "\n",
    "We want you to find the best model for the task. Use everything you know.\n",
    "\n",
    "* different recurrent units: rnn/gru/lstm; deeper architectures\n",
    "* bidirectional encoder, different attention methods for decoder (additive, dot-product, multi-head)\n",
    "* word dropout, training schedules, anything you can imagine\n",
    "* replace greedy inference with beam search\n",
    "\n",
    "For a better grasp of seq2seq We recommend you to conduct at least one experiment from one of the bullet-points or your alternative ideas. As usual, describe what you tried and what results you obtained in a short report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "2rzAj_xtlrtt"
   },
   "source": [
    "`[your report/log here or anywhere you please]`"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "edk_oVg0lrtW"
   ],
   "name": "practice.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
